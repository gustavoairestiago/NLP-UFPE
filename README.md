# Classificador de AvaliaÃ§Ãµes de Produto

Este repositÃ³rio contÃ©m um projeto voltado para anÃ¡lise de avaliaÃ§Ãµes de um produto especÃ­fico, utilizando tÃ©cnicas de aprendizado de mÃ¡quina e processamento de linguagem natural para classificaÃ§Ã£o de sentimentos. O projeto inclui trÃªs abordagens distintas de classificaÃ§Ã£o.

## Link para o vÃ­deo de apresentaÃ§Ã£o
https://youtu.be/AC6o_nZEEeg

## Objetivos

1. **Treinar classificadores:** Comparar diferentes tÃ©cnicas de classificaÃ§Ã£o de sentimentos:
   - SVM + Bag of Words (BoW)
   - SVM + Embeddings
   - BERT (Bidirectional Encoder Representations from Transformers)

---

## Estrutura do Projeto

```
ğŸ“‚ projeto
â”œâ”€â”€ ğŸ“ data            # DiretÃ³rio para armazenamento dos dados coletados
â”œâ”€â”€ ğŸ“ notebooks       # Notebooks Jupyter para exploraÃ§Ã£o e treinamento
â”œâ”€â”€ ğŸ“ apresentaÃ§Ã£o    # ApresentaÃ§Ã£o com resultados e mÃ©tricas de avaliaÃ§Ã£o dos modelos
â””â”€â”€ ğŸ“„ README.md       # Este arquivo
```

---

## Etapas do Projeto

### 1. Coleta de Dados
- **Fonte:** AvaliaÃ§Ãµes coletadas da Amazon.
- **Campos:** Texto da avaliaÃ§Ã£o, nota atribuÃ­da pelo usuÃ¡rio.

### 2. PrÃ©-processamento
- TokenizaÃ§Ã£o
- Limpeza de texto (remoÃ§Ã£o de stopwords, pontuaÃ§Ãµes, etc.)
- RepresentaÃ§Ã£o textual (BoW, embeddings ou tokenizaÃ§Ã£o do BERT).

### 3. Treinamento dos Modelos
- **SVM + BoW:** Baseado em contagem ou frequÃªncia de palavras.
- **SVM + Embeddings:** Utiliza vetores prÃ©-treinados (e.g., GloVe, Word2Vec).
- **BERT:** Modelo prÃ©-treinado para representaÃ§Ã£o contextualizada de texto.

### 4. AvaliaÃ§Ã£o
- MÃ©tricas utilizadas: AcurÃ¡cia, F1-Score, Precision e Recall.
- ComparaÃ§Ã£o entre as abordagens para determinar a melhor performance.

---

## Tecnologias Utilizadas

- **Linguagens:** Python
- **Bibliotecas:**
  - Pandas, NumPy (manipulaÃ§Ã£o de dados)
  - Scikit-learn (SVM e validaÃ§Ã£o)
  - TensorFlow / PyTorch (BERT)
  - NLTK / SpaCy (processamento de texto)
  - Matplotlib / Seaborn (visualizaÃ§Ã£o de dados)

---
